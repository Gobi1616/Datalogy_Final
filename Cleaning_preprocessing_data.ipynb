{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ad9a12",
   "metadata": {},
   "source": [
    "# (1) Twitter Data\n",
    "## (1.1) Getting Twitter data 2021 from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e87ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from path import Path\n",
    "from twarc import Twarc2, expansions\n",
    "import json\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7095c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f34565",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=bearer_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9190bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 'elonmusk'\n",
    "posts_dict = {\n",
    "    'date':[],\n",
    "    'text':[],\n",
    "    'like_count':[],\n",
    "    'reply_count':[],\n",
    "    'retweet_count':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60457707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull posts from Twitter and create a dictionary\n",
    "user_timeline = client.timeline(user=user, exclude_replies=True, start_time=datetime.datetime(2021,1,1, 0, 0, 0) )\n",
    "for page in user_timeline:\n",
    "    result = expansions.flatten(page)\n",
    "    for tweet in result:\n",
    "        posts_dict['date'].append(tweet['created_at'])\n",
    "        posts_dict['text'].append(tweet['text'])\n",
    "        posts_dict['like_count'].append(tweet['public_metrics']['like_count'])\n",
    "        posts_dict['reply_count'].append(tweet['public_metrics']['reply_count'])\n",
    "        posts_dict['retweet_count'].append(tweet['public_metrics']['retweet_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cd366b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-18T23:13:01.000Z</td>\n",
       "      <td>Congratulations @Inspiration4x!!!</td>\n",
       "      <td>111742</td>\n",
       "      <td>6227</td>\n",
       "      <td>7878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-18T23:12:22.000Z</td>\n",
       "      <td>RT @SpaceX: Splashdown! Welcome back to planet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-18T21:41:06.000Z</td>\n",
       "      <td>RT @SpaceX: Dragon has entered its last orbit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-18T19:01:40.000Z</td>\n",
       "      <td>RT @SpaceX: Orbital moonrise https://t.co/vrx8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-18T04:54:38.000Z</td>\n",
       "      <td>Moving at ~23 times speed of sound, circling E...</td>\n",
       "      <td>99941</td>\n",
       "      <td>4379</td>\n",
       "      <td>9596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  \\\n",
       "0  2021-09-18T23:13:01.000Z   \n",
       "1  2021-09-18T23:12:22.000Z   \n",
       "2  2021-09-18T21:41:06.000Z   \n",
       "3  2021-09-18T19:01:40.000Z   \n",
       "4  2021-09-18T04:54:38.000Z   \n",
       "\n",
       "                                                text  like_count  reply_count  \\\n",
       "0                  Congratulations @Inspiration4x!!!      111742         6227   \n",
       "1  RT @SpaceX: Splashdown! Welcome back to planet...           0            0   \n",
       "2  RT @SpaceX: Dragon has entered its last orbit ...           0            0   \n",
       "3  RT @SpaceX: Orbital moonrise https://t.co/vrx8...           0            0   \n",
       "4  Moving at ~23 times speed of sound, circling E...       99941         4379   \n",
       "\n",
       "   retweet_count  \n",
       "0           7878  \n",
       "1          15445  \n",
       "2           2076  \n",
       "3           4585  \n",
       "4           9596  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert dictionary of posts to dataframe\n",
    "twitter_2021 = pd.DataFrame.from_dict(posts_dict)\n",
    "twitter_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6c5a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>This is called the domino effect https://t.co/...</td>\n",
       "      <td>363374</td>\n",
       "      <td>4442</td>\n",
       "      <td>36994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>Because of the large footprint, it may seem fl...</td>\n",
       "      <td>57381</td>\n",
       "      <td>1368</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>Snow falling on Giga Berlin https://t.co/eTXMt...</td>\n",
       "      <td>147180</td>\n",
       "      <td>3609</td>\n",
       "      <td>6790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>So proud of the Tesla team for achieving this ...</td>\n",
       "      <td>108925</td>\n",
       "      <td>4104</td>\n",
       "      <td>6157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>RT @Tesla: In 2020, we produced and delivered ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                               text  like_count  \\\n",
       "542 2021-01-07  This is called the domino effect https://t.co/...      363374   \n",
       "543 2021-01-04  Because of the large footprint, it may seem fl...       57381   \n",
       "544 2021-01-04  Snow falling on Giga Berlin https://t.co/eTXMt...      147180   \n",
       "545 2021-01-02  So proud of the Tesla team for achieving this ...      108925   \n",
       "546 2021-01-02  RT @Tesla: In 2020, we produced and delivered ...           0   \n",
       "\n",
       "     reply_count  retweet_count  \n",
       "542         4442          36994  \n",
       "543         1368           1055  \n",
       "544         3609           6790  \n",
       "545         4104           6157  \n",
       "546            0           6175  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert date to datetime datatype\n",
    "twitter_2021['date'] = pd.to_datetime(twitter_2021['date']).dt.date.astype('datetime64')\n",
    "twitter_2021.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c1164c",
   "metadata": {},
   "source": [
    "## (1.2) Getting Twitter data 2011 - 2020 from archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d025f401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>timezone</th>\n",
       "      <th>place</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1343644462036086785</td>\n",
       "      <td>1343320495127633920</td>\n",
       "      <td>1.609185e+12</td>\n",
       "      <td>2020-12-28 19:46:18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Entertainment will be critical when cars drive...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1343619610617077760</td>\n",
       "      <td>1343386617294295040</td>\n",
       "      <td>1.609179e+12</td>\n",
       "      <td>2020-12-28 18:07:33</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@kimpaquette Just meeting with Larry Ellison t...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'kimpaquette', 'name': 'Kim P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1343608616960491521</td>\n",
       "      <td>1343576442722893825</td>\n",
       "      <td>1.609176e+12</td>\n",
       "      <td>2020-12-28 17:23:51</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@richierichhhhh_ Absolutely</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'richierichhhhh_', 'name': 'R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1343608530998153222</td>\n",
       "      <td>1343320495127633920</td>\n",
       "      <td>1.609176e+12</td>\n",
       "      <td>2020-12-28 17:23:31</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What should Tesla do with in-car gaming in an ...</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1343431408052662273</td>\n",
       "      <td>1343043963096326147</td>\n",
       "      <td>1.609134e+12</td>\n",
       "      <td>2020-12-28 05:39:42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@PPathole @WSJ Absolutely</td>\n",
       "      <td>en</td>\n",
       "      <td>[]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'screen_name': 'PPathole', 'name': 'Pranay P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                   id      conversation_id    created_at  \\\n",
       "0           0  1343644462036086785  1343320495127633920  1.609185e+12   \n",
       "1           1  1343619610617077760  1343386617294295040  1.609179e+12   \n",
       "2           2  1343608616960491521  1343576442722893825  1.609176e+12   \n",
       "3           3  1343608530998153222  1343320495127633920  1.609176e+12   \n",
       "4           4  1343431408052662273  1343043963096326147  1.609134e+12   \n",
       "\n",
       "                  date  timezone  place  \\\n",
       "0  2020-12-28 19:46:18         0    NaN   \n",
       "1  2020-12-28 18:07:33         0    NaN   \n",
       "2  2020-12-28 17:23:51         0    NaN   \n",
       "3  2020-12-28 17:23:31         0    NaN   \n",
       "4  2020-12-28 05:39:42         0    NaN   \n",
       "\n",
       "                                               tweet language hashtags  ...  \\\n",
       "0  Entertainment will be critical when cars drive...       en       []  ...   \n",
       "1  @kimpaquette Just meeting with Larry Ellison t...       en       []  ...   \n",
       "2                        @richierichhhhh_ Absolutely       en       []  ...   \n",
       "3  What should Tesla do with in-car gaming in an ...       en       []  ...   \n",
       "4                          @PPathole @WSJ Absolutely       en       []  ...   \n",
       "\n",
       "  geo  source  user_rt_id user_rt retweet_id  \\\n",
       "0 NaN     NaN         NaN     NaN        NaN   \n",
       "1 NaN     NaN         NaN     NaN        NaN   \n",
       "2 NaN     NaN         NaN     NaN        NaN   \n",
       "3 NaN     NaN         NaN     NaN        NaN   \n",
       "4 NaN     NaN         NaN     NaN        NaN   \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0                                                 []           NaN       NaN   \n",
       "1  [{'screen_name': 'kimpaquette', 'name': 'Kim P...           NaN       NaN   \n",
       "2  [{'screen_name': 'richierichhhhh_', 'name': 'R...           NaN       NaN   \n",
       "3                                                 []           NaN       NaN   \n",
       "4  [{'screen_name': 'PPathole', 'name': 'Pranay P...           NaN       NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load twitter data from csv file\n",
    "file_to_load = os.path.join('Data', 'elon_musk_tweets_2011-2021.csv')\n",
    "twitter_archive = pd.read_csv(file_to_load)\n",
    "twitter_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f95bfbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>Entertainment will be critical when cars drive...</td>\n",
       "      <td>55085</td>\n",
       "      <td>2922</td>\n",
       "      <td>2611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>What should Tesla do with in-car gaming in an ...</td>\n",
       "      <td>33830</td>\n",
       "      <td>6932</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>Try playing Polytopia in your Tesla! Great gam...</td>\n",
       "      <td>148037</td>\n",
       "      <td>5355</td>\n",
       "      <td>4186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>Change your horn sound to üêê, üêçüé∑, üí® or holiday ...</td>\n",
       "      <td>187368</td>\n",
       "      <td>5373</td>\n",
       "      <td>6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-12-25</td>\n",
       "      <td>Merry Christmas &amp;amp; happy holidays! üéÅ  https...</td>\n",
       "      <td>236833</td>\n",
       "      <td>7496</td>\n",
       "      <td>13288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               text  like_count  \\\n",
       "0  2020-12-28  Entertainment will be critical when cars drive...       55085   \n",
       "3  2020-12-28  What should Tesla do with in-car gaming in an ...       33830   \n",
       "6  2020-12-27  Try playing Polytopia in your Tesla! Great gam...      148037   \n",
       "34 2020-12-25  Change your horn sound to üêê, üêçüé∑, üí® or holiday ...      187368   \n",
       "35 2020-12-25  Merry Christmas &amp; happy holidays! üéÅ  https...      236833   \n",
       "\n",
       "    reply_count  retweet_count  \n",
       "0          2922           2611  \n",
       "3          6932            884  \n",
       "6          5355           4186  \n",
       "34         5373           6983  \n",
       "35         7496          13288  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select and rename columns\n",
    "twitter_archive_clean = twitter_archive[['date', 'tweet', 'nlikes', 'nreplies', 'nretweets']]\\\n",
    "                            .loc[(twitter_archive['reply_to'] == '[]') & (twitter_archive['retweet'] == False)]\n",
    "twitter_archive_clean.columns=['date', 'text', 'like_count', 'reply_count', 'retweet_count']\n",
    "\n",
    "# convert date to datetime datatype\n",
    "twitter_archive_clean['date'] = pd.to_datetime(twitter_archive_clean['date']).dt.date.astype('datetime64')\n",
    "\n",
    "# drop last row with 1 tweet in 2011\n",
    "twitter_archive_clean.drop(twitter_archive_clean.tail(1).index,inplace=True)\n",
    "\n",
    "twitter_archive_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92c62e0",
   "metadata": {},
   "source": [
    "## (1.3) Clean the twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b87bb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4732 entries, 0 to 11715\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype         \n",
      "---  ------         --------------  -----         \n",
      " 0   date           4732 non-null   datetime64[ns]\n",
      " 1   text           4732 non-null   object        \n",
      " 2   like_count     4732 non-null   int64         \n",
      " 3   reply_count    4732 non-null   int64         \n",
      " 4   retweet_count  4732 non-null   int64         \n",
      "dtypes: datetime64[ns](1), int64(3), object(1)\n",
      "memory usage: 221.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# concatenate 2 datasets to get tweets from 2011 to 2021\n",
    "twitter_df_merged = pd.concat([twitter_2021, twitter_archive_clean])\n",
    "twitter_df_merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "971be6ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>Congratulations @Inspiration4x!!!</td>\n",
       "      <td>111742</td>\n",
       "      <td>6227</td>\n",
       "      <td>7878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>RT @SpaceX: Splashdown! Welcome back to planet...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>RT @SpaceX: Dragon has entered its last orbit ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>RT @SpaceX: Orbital moonrise https://t.co/vrx8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-18</td>\n",
       "      <td>Moving at ~23 times speed of sound, circling E...</td>\n",
       "      <td>99941</td>\n",
       "      <td>4379</td>\n",
       "      <td>9596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11711</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>Am reading a great biography of Ben Franklin b...</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11712</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11713</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11714</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>I made the volume on the Model S  http://t.co/...</td>\n",
       "      <td>78</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11715</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "      <td>189</td>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4732 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                               text  \\\n",
       "0     2021-09-18                  Congratulations @Inspiration4x!!!   \n",
       "1     2021-09-18  RT @SpaceX: Splashdown! Welcome back to planet...   \n",
       "2     2021-09-18  RT @SpaceX: Dragon has entered its last orbit ...   \n",
       "3     2021-09-18  RT @SpaceX: Orbital moonrise https://t.co/vrx8...   \n",
       "4     2021-09-18  Moving at ~23 times speed of sound, circling E...   \n",
       "...          ...                                                ...   \n",
       "11711 2011-12-04  Am reading a great biography of Ben Franklin b...   \n",
       "11712 2011-12-03                  That was a total non sequitur btw   \n",
       "11713 2011-12-03  Great Voltaire quote, arguably better than Twa...   \n",
       "11714 2011-12-01  I made the volume on the Model S  http://t.co/...   \n",
       "11715 2011-12-01  Went to Iceland on Sat to ride bumper cars on ...   \n",
       "\n",
       "       like_count  reply_count  retweet_count  \n",
       "0          111742         6227           7878  \n",
       "1               0            0          15445  \n",
       "2               0            0           2076  \n",
       "3               0            0           4585  \n",
       "4           99941         4379           9596  \n",
       "...           ...          ...            ...  \n",
       "11711          65           17              9  \n",
       "11712          53           31              6  \n",
       "11713          29            7             25  \n",
       "11714          78           31              9  \n",
       "11715         189           32             15  \n",
       "\n",
       "[4732 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the NaNs\n",
    "twitter_df_merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3abdaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export all tweets for analysis in Tableau\n",
    "twitter_df_merged.to_csv('Data/tweets_data_2011_2021_ungrouped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db23122e",
   "metadata": {},
   "source": [
    "## (1.4) Preprocessing the Twitter data\n",
    "\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8530984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gobinaththangaiya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b731df31",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# group tweets that posted at the same day\n",
    "def f(x):\n",
    "     return pd.Series(dict(like_count = x['like_count'].sum(),\n",
    "                        reply_count = x['reply_count'].sum(),\n",
    "                        retweet_count = x['retweet_count'].sum(),\n",
    "                        text = \"{%s}\" % ', '.join(x['text'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d661c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>1330</td>\n",
       "      <td>87</td>\n",
       "      <td>597</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>1349</td>\n",
       "      <td>132</td>\n",
       "      <td>206</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  like_count  reply_count  retweet_count  \\\n",
       "0 2011-12-01         267           63             24   \n",
       "1 2011-12-03          82           38             31   \n",
       "2 2011-12-04          65           17              9   \n",
       "3 2011-12-21        1330           87            597   \n",
       "4 2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \n",
       "0  {I made the volume on the Model S  http://t.co...  \n",
       "1  {That was a total non sequitur btw, Great Volt...  \n",
       "2  {Am reading a great biography of Ben Franklin ...  \n",
       "3  {Yum! Even better than deep fried butter:  htt...  \n",
       "4  {Model S options are out! Performance in red a...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df_merged = twitter_df_merged.groupby('date').apply(f).reset_index()\n",
    "twitter_df_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61a68df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             1767\n",
       "like_count       1767\n",
       "reply_count      1767\n",
       "retweet_count    1767\n",
       "text             1767\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df_merged.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57afb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = twitter_df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0fd768a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "      <td>{i made the volume on the model s go to 11. no...</td>\n",
       "      <td>[made, volume, model, go, need, work, miniatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "      <td>{that was a total non sequitur btw, great volt...</td>\n",
       "      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "      <td>{am reading a great biography of ben franklin ...</td>\n",
       "      <td>[reading, great, biography, ben, franklin, isa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>1330</td>\n",
       "      <td>87</td>\n",
       "      <td>597</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "      <td>{yum! even better than deep fried butter: yeah...</td>\n",
       "      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>1349</td>\n",
       "      <td>132</td>\n",
       "      <td>206</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "      <td>{model s options are out! performance in red a...</td>\n",
       "      <td>[model, options, performance, red, black, deli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  like_count  reply_count  retweet_count  \\\n",
       "0 2011-12-01         267           63             24   \n",
       "1 2011-12-03          82           38             31   \n",
       "2 2011-12-04          65           17              9   \n",
       "3 2011-12-21        1330           87            597   \n",
       "4 2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \\\n",
       "0  {I made the volume on the Model S  http://t.co...   \n",
       "1  {That was a total non sequitur btw, Great Volt...   \n",
       "2  {Am reading a great biography of Ben Franklin ...   \n",
       "3  {Yum! Even better than deep fried butter:  htt...   \n",
       "4  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {i made the volume on the model s go to 11. no...   \n",
       "1  {that was a total non sequitur btw, great volt...   \n",
       "2  {am reading a great biography of ben franklin ...   \n",
       "3  {yum! even better than deep fried butter: yeah...   \n",
       "4  {model s options are out! performance in red a...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [made, volume, model, go, need, work, miniatur...  \n",
       "1  [total, non, sequitur, great, voltaire, quote,...  \n",
       "2  [reading, great, biography, ben, franklin, isa...  \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...  \n",
       "4  [model, options, performance, red, black, deli...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_text'] = twitter_df['text'].str.lower()\n",
    "\n",
    "# remove apostrophe from words and url\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"('[a-z]+)\\s\", \" \", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(')\\s\", \" \", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(?:https:\\/\\/\\S+)\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "\n",
    "                                      \n",
    "# filter out rest URLs\n",
    "url_re = '(?:https?:\\/\\/)?(?:[^?\\/\\s]+[?\\/])(.*)'\n",
    "twitter_df['preprocessed_text'] = twitter_df['preprocessed_text'].apply(lambda row: ' '.join([word for word in row.split() if (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "twitter_df['tokenized_text'] = twitter_df['preprocessed_text'].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemming\n",
    "twitter_df['preprocessed_text'] = [porter.stem(row) for row in twitter_df['preprocessed_text']]   \n",
    "\n",
    "# filter out stop words\n",
    "en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "additional_stop_words =['amp', 'rt', 'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii', 'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt', 'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', 'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here‚Äôs', 're', 'mqxfakpzf' 'mph', 'ht', 'etc', 'dm', 'doo']\n",
    "en_stop_words.extend(additional_stop_words)\n",
    "\n",
    "twitter_df['tokenized_text'] = twitter_df['tokenized_text'].apply(lambda row: [word for word in row if (not word in en_stop_words)])\n",
    "\n",
    "df_tweets_clean = twitter_df.copy()\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caba4f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "      <td>[made, volume, model, go, need, work, miniatur...</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "      <td>[reading, great, biography, ben, franklin, isa...</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n",
       "      <td>1330</td>\n",
       "      <td>87</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "      <td>[model, options, performance, red, black, deli...</td>\n",
       "      <td>1349</td>\n",
       "      <td>132</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-12-24</td>\n",
       "      <td>{The Russians are having some challenges with ...</td>\n",
       "      <td>[russians, challenges, rockets, many, engineer...</td>\n",
       "      <td>117113</td>\n",
       "      <td>1370</td>\n",
       "      <td>8434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-12-26</td>\n",
       "      <td>{Walked around a neighborhood recently rebuilt...</td>\n",
       "      <td>[walked, around, neighborhood, recently, rebui...</td>\n",
       "      <td>558</td>\n",
       "      <td>102</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-12-27</td>\n",
       "      <td>{If you ever wanted to know the *real* truth a...</td>\n",
       "      <td>[ever, wanted, know, real, truth, moon, landin...</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-12-28</td>\n",
       "      <td>{@TheOnion So true :)}</td>\n",
       "      <td>[theonion, true]</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-12-29</td>\n",
       "      <td>{Am not saying that is *necessarily* good or b...</td>\n",
       "      <td>[saying, necessarily, good, bad, reality, forc...</td>\n",
       "      <td>187</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text  \\\n",
       "0 2011-12-01  {I made the volume on the Model S  http://t.co...   \n",
       "1 2011-12-03  {That was a total non sequitur btw, Great Volt...   \n",
       "2 2011-12-04  {Am reading a great biography of Ben Franklin ...   \n",
       "3 2011-12-21  {Yum! Even better than deep fried butter:  htt...   \n",
       "4 2011-12-22  {Model S options are out! Performance in red a...   \n",
       "5 2011-12-24  {The Russians are having some challenges with ...   \n",
       "6 2011-12-26  {Walked around a neighborhood recently rebuilt...   \n",
       "7 2011-12-27  {If you ever wanted to know the *real* truth a...   \n",
       "8 2011-12-28                             {@TheOnion So true :)}   \n",
       "9 2011-12-29  {Am not saying that is *necessarily* good or b...   \n",
       "\n",
       "                                      tokenized_text  like_count  reply_count  \\\n",
       "0  [made, volume, model, go, need, work, miniatur...         267           63   \n",
       "1  [total, non, sequitur, great, voltaire, quote,...          82           38   \n",
       "2  [reading, great, biography, ben, franklin, isa...          65           17   \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...        1330           87   \n",
       "4  [model, options, performance, red, black, deli...        1349          132   \n",
       "5  [russians, challenges, rockets, many, engineer...      117113         1370   \n",
       "6  [walked, around, neighborhood, recently, rebui...         558          102   \n",
       "7  [ever, wanted, know, real, truth, moon, landin...          39           13   \n",
       "8                                   [theonion, true]          12            7   \n",
       "9  [saying, necessarily, good, bad, reality, forc...         187           39   \n",
       "\n",
       "   retweet_count  \n",
       "0             24  \n",
       "1             31  \n",
       "2              9  \n",
       "3            597  \n",
       "4            206  \n",
       "5           8434  \n",
       "6            171  \n",
       "7             34  \n",
       "8              1  \n",
       "9             41  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets_clean = df_tweets_clean[['date', 'text', 'tokenized_text', 'like_count', 'reply_count', 'retweet_count']]\n",
    "df_tweets_clean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6338deb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8253"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count unique words\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]\n",
    "  \n",
    "len(get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "effaa3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_csv('data/tweets_data_2011_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10cef55",
   "metadata": {},
   "source": [
    "## (1.5) Upload dataset to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbdcd9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, inspect\n",
    "import psycopg2\n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c83bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "# engine = create_engine(f'postgresql+psycopg2://{user}:{password}@{hostname}/twitter_vs_stocks')\n",
    "engine = create_engine(f\"postgresql://postgres:{db_password}@127.0.0.1:5432/twitter_vs_stocks\")\n",
    "# Use the Inspector to explore the database\n",
    "inspector = inspect(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76530bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets_clean.to_sql('tweets_text', engine, if_exists ='replace',method='multi', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf788124",
   "metadata": {},
   "source": [
    "# (2 ) Stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c8153",
   "metadata": {},
   "source": [
    "## (2.1) Getting the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5ee54ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "725dce38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>5.368000</td>\n",
       "      <td>5.400000</td>\n",
       "      <td>5.180000</td>\n",
       "      <td>5.324000</td>\n",
       "      <td>5.324000</td>\n",
       "      <td>6415000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>5.332000</td>\n",
       "      <td>5.390000</td>\n",
       "      <td>5.204000</td>\n",
       "      <td>5.334000</td>\n",
       "      <td>5.334000</td>\n",
       "      <td>5937000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>5.296000</td>\n",
       "      <td>5.380000</td>\n",
       "      <td>5.238000</td>\n",
       "      <td>5.366000</td>\n",
       "      <td>5.366000</td>\n",
       "      <td>7233500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>5.366000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.362000</td>\n",
       "      <td>5.576000</td>\n",
       "      <td>5.576000</td>\n",
       "      <td>10306000</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>5.716000</td>\n",
       "      <td>5.580000</td>\n",
       "      <td>5.648000</td>\n",
       "      <td>5.648000</td>\n",
       "      <td>11239500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>2021-09-13</td>\n",
       "      <td>740.210022</td>\n",
       "      <td>744.780029</td>\n",
       "      <td>708.849976</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>743.000000</td>\n",
       "      <td>22952500</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2692</th>\n",
       "      <td>2021-09-14</td>\n",
       "      <td>742.570007</td>\n",
       "      <td>754.469971</td>\n",
       "      <td>736.400024</td>\n",
       "      <td>744.489990</td>\n",
       "      <td>744.489990</td>\n",
       "      <td>18524900</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>2021-09-15</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>756.859985</td>\n",
       "      <td>738.359985</td>\n",
       "      <td>755.830017</td>\n",
       "      <td>755.830017</td>\n",
       "      <td>15357700</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>752.830017</td>\n",
       "      <td>758.909973</td>\n",
       "      <td>747.609985</td>\n",
       "      <td>756.989990</td>\n",
       "      <td>756.989990</td>\n",
       "      <td>13923400</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2695</th>\n",
       "      <td>2021-09-17</td>\n",
       "      <td>757.150024</td>\n",
       "      <td>761.039978</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>759.489990</td>\n",
       "      <td>759.489990</td>\n",
       "      <td>28186100</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2696 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date        open        high         low       close    adjclose  \\\n",
       "0    2011-01-03    5.368000    5.400000    5.180000    5.324000    5.324000   \n",
       "1    2011-01-04    5.332000    5.390000    5.204000    5.334000    5.334000   \n",
       "2    2011-01-05    5.296000    5.380000    5.238000    5.366000    5.366000   \n",
       "3    2011-01-06    5.366000    5.600000    5.362000    5.576000    5.576000   \n",
       "4    2011-01-07    5.600000    5.716000    5.580000    5.648000    5.648000   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "2691 2021-09-13  740.210022  744.780029  708.849976  743.000000  743.000000   \n",
       "2692 2021-09-14  742.570007  754.469971  736.400024  744.489990  744.489990   \n",
       "2693 2021-09-15  745.000000  756.859985  738.359985  755.830017  755.830017   \n",
       "2694 2021-09-16  752.830017  758.909973  747.609985  756.989990  756.989990   \n",
       "2695 2021-09-17  757.150024  761.039978  750.000000  759.489990  759.489990   \n",
       "\n",
       "        volume ticker  \n",
       "0      6415000   TSLA  \n",
       "1      5937000   TSLA  \n",
       "2      7233500   TSLA  \n",
       "3     10306000   TSLA  \n",
       "4     11239500   TSLA  \n",
       "...        ...    ...  \n",
       "2691  22952500   TSLA  \n",
       "2692  18524900   TSLA  \n",
       "2693  15357700   TSLA  \n",
       "2694  13923400   TSLA  \n",
       "2695  28186100   TSLA  \n",
       "\n",
       "[2696 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# historical daily data from Yahoo finance\n",
    "tesla_df = get_data(\"tsla\", start_date = '2011-01-01', end_date = None, index_as_date = False, interval=\"1d\")\n",
    "tesla_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e57be6",
   "metadata": {},
   "source": [
    "## (2.2) Clean the stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72eba53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>5.368</td>\n",
       "      <td>5.400</td>\n",
       "      <td>5.180</td>\n",
       "      <td>5.324</td>\n",
       "      <td>6415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>5.332</td>\n",
       "      <td>5.390</td>\n",
       "      <td>5.204</td>\n",
       "      <td>5.334</td>\n",
       "      <td>5937000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>5.296</td>\n",
       "      <td>5.380</td>\n",
       "      <td>5.238</td>\n",
       "      <td>5.366</td>\n",
       "      <td>7233500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>5.366</td>\n",
       "      <td>5.600</td>\n",
       "      <td>5.362</td>\n",
       "      <td>5.576</td>\n",
       "      <td>10306000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>5.600</td>\n",
       "      <td>5.716</td>\n",
       "      <td>5.580</td>\n",
       "      <td>5.648</td>\n",
       "      <td>11239500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume\n",
       "0 2011-01-03  5.368  5.400  5.180  5.324   6415000\n",
       "1 2011-01-04  5.332  5.390  5.204  5.334   5937000\n",
       "2 2011-01-05  5.296  5.380  5.238  5.366   7233500\n",
       "3 2011-01-06  5.366  5.600  5.362  5.576  10306000\n",
       "4 2011-01-07  5.600  5.716  5.580  5.648  11239500"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop adjclose column\n",
    "tesla_df = tesla_df.drop(columns=[\"adjclose\", \"ticker\"])\n",
    "tesla_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fff742f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date      datetime64[ns]\n",
       "open             float64\n",
       "high             float64\n",
       "low              float64\n",
       "close            float64\n",
       "volume             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine data types for each column\n",
    "tesla_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adc19c0",
   "metadata": {},
   "source": [
    "## (2.3) Preprocessing the Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f772a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>5.368</td>\n",
       "      <td>5.400</td>\n",
       "      <td>5.180</td>\n",
       "      <td>5.324</td>\n",
       "      <td>6415000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>5.332</td>\n",
       "      <td>5.390</td>\n",
       "      <td>5.204</td>\n",
       "      <td>5.334</td>\n",
       "      <td>5937000</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>5.296</td>\n",
       "      <td>5.380</td>\n",
       "      <td>5.238</td>\n",
       "      <td>5.366</td>\n",
       "      <td>7233500</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-06</td>\n",
       "      <td>5.366</td>\n",
       "      <td>5.600</td>\n",
       "      <td>5.362</td>\n",
       "      <td>5.576</td>\n",
       "      <td>10306000</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>5.600</td>\n",
       "      <td>5.716</td>\n",
       "      <td>5.580</td>\n",
       "      <td>5.648</td>\n",
       "      <td>11239500</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2011-01-10</td>\n",
       "      <td>5.634</td>\n",
       "      <td>5.736</td>\n",
       "      <td>5.610</td>\n",
       "      <td>5.690</td>\n",
       "      <td>6713500</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2011-01-11</td>\n",
       "      <td>5.718</td>\n",
       "      <td>5.742</td>\n",
       "      <td>5.384</td>\n",
       "      <td>5.392</td>\n",
       "      <td>8551000</td>\n",
       "      <td>-0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2011-01-12</td>\n",
       "      <td>5.402</td>\n",
       "      <td>5.480</td>\n",
       "      <td>5.304</td>\n",
       "      <td>5.392</td>\n",
       "      <td>4822000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>5.392</td>\n",
       "      <td>5.394</td>\n",
       "      <td>5.232</td>\n",
       "      <td>5.244</td>\n",
       "      <td>3618000</td>\n",
       "      <td>-0.148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2011-01-14</td>\n",
       "      <td>5.230</td>\n",
       "      <td>5.316</td>\n",
       "      <td>5.122</td>\n",
       "      <td>5.150</td>\n",
       "      <td>5960000</td>\n",
       "      <td>-0.094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date   open   high    low  close    volume  change\n",
       "0 2011-01-03  5.368  5.400  5.180  5.324   6415000     NaN\n",
       "1 2011-01-04  5.332  5.390  5.204  5.334   5937000   0.010\n",
       "2 2011-01-05  5.296  5.380  5.238  5.366   7233500   0.032\n",
       "3 2011-01-06  5.366  5.600  5.362  5.576  10306000   0.210\n",
       "4 2011-01-07  5.600  5.716  5.580  5.648  11239500   0.072\n",
       "5 2011-01-10  5.634  5.736  5.610  5.690   6713500   0.042\n",
       "6 2011-01-11  5.718  5.742  5.384  5.392   8551000  -0.298\n",
       "7 2011-01-12  5.402  5.480  5.304  5.392   4822000   0.000\n",
       "8 2011-01-13  5.392  5.394  5.232  5.244   3618000  -0.148\n",
       "9 2011-01-14  5.230  5.316  5.122  5.150   5960000  -0.094"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate change in stock price\n",
    "tesla_df['change'] = tesla_df['close'].diff()\n",
    "tesla_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d712d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_csv('data/tesla_stocks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426185f",
   "metadata": {},
   "source": [
    "## (2.4) Upload dataset to SQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d70ef683",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla_df.to_sql('stock', engine, if_exists ='replace',method='multi', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e7dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82f3a362",
   "metadata": {},
   "source": [
    "# Machine Learning Model - Second Segment Project Deliverable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f8b11",
   "metadata": {},
   "source": [
    "## Model Plan\n",
    "- Prepare the dataframe with columns: tweet_text, price_previous day, price_next day, price_diff\n",
    "- Preprocess the tweet text into features (countVectorier, tfidf)\n",
    "- Classification: LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a412b2b",
   "metadata": {},
   "source": [
    "### Query the dataframe with columns: tweet_text, price_previous day, price_next day, price_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af82539e-5e32-4859-b979-65da960922b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries:\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect \n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af61d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f\"postgresql://postgres:{db_password}@127.0.0.1:5432/twitter_vs_stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8ffe9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new table for model, preprocessing the data\n",
    "\n",
    "tweets_price = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "        SELECT \n",
    "            tweets.date AS tweet_date,\n",
    "            tweets.text AS tweet_text,\n",
    "            tweets.tokenized_text AS tweet_tokens,\n",
    "            COALESCE(stock_prev.close, stock_prev_prev.close, stock_prev_prev_prev.close) AS prev_day_close,\n",
    "            COALESCE(stock_next.close, stock_next_next.close, stock_next_next_next.close) AS next_day_close\n",
    "        FROM tweets_text tweets\n",
    "        LEFT JOIN stock stock_prev\n",
    "            ON (tweets.date - INTERVAL '1 day') = stock_prev.date\n",
    "        LEFT JOIN stock stock_prev_prev\n",
    "            ON (tweets.date - INTERVAL '2 day') = stock_prev_prev.date\n",
    "        LEFT JOIN stock stock_prev_prev_prev\n",
    "            ON (tweets.date - INTERVAL '3 day') = stock_prev_prev_prev.date\n",
    "        LEFT JOIN stock stock_next\n",
    "            ON (tweets.date + INTERVAL '1 day') = stock_next.date\n",
    "        LEFT JOIN stock stock_next_next\n",
    "            ON (tweets.date + INTERVAL '2 day') = stock_next_next.date\n",
    "        LEFT JOIN stock stock_next_next_next\n",
    "            ON (tweets.date + INTERVAL '3 day') = stock_next_next_next.date\n",
    "        WHERE tweets.date > '2011-01-01' AND tweets.tokenized_text != '{}'\n",
    "        ORDER BY tweets.date\n",
    "    \"\"\",\n",
    "    con=engine\n",
    ")\n",
    "\n",
    "tweets_price.dropna(inplace=True)\n",
    "\n",
    "#Computing difference between the stock price before the date of tweet and after the post. \n",
    "tweets_price['close_price_diff'] = tweets_price['next_day_close'] - tweets_price['prev_day_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a831805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>prev_day_close</th>\n",
       "      <th>next_day_close</th>\n",
       "      <th>close_price_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "      <td>{made,volume,model,go,need,work,miniature,ston...</td>\n",
       "      <td>6.548</td>\n",
       "      <td>6.660</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "      <td>{total,non,sequitur,great,voltaire,quote,argua...</td>\n",
       "      <td>6.660</td>\n",
       "      <td>6.884</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "      <td>{reading,great,biography,ben,franklin,isaacson...</td>\n",
       "      <td>6.660</td>\n",
       "      <td>6.884</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "      <td>{yum,even,better,deep,fried,butter,yeah,really...</td>\n",
       "      <td>5.580</td>\n",
       "      <td>5.554</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "      <td>{model,options,performance,red,black,deliver,c...</td>\n",
       "      <td>5.514</td>\n",
       "      <td>5.580</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_date                                         tweet_text  \\\n",
       "0 2011-12-01  {I made the volume on the Model S  http://t.co...   \n",
       "1 2011-12-03  {That was a total non sequitur btw, Great Volt...   \n",
       "2 2011-12-04  {Am reading a great biography of Ben Franklin ...   \n",
       "3 2011-12-21  {Yum! Even better than deep fried butter:  htt...   \n",
       "4 2011-12-22  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                        tweet_tokens  prev_day_close  \\\n",
       "0  {made,volume,model,go,need,work,miniature,ston...           6.548   \n",
       "1  {total,non,sequitur,great,voltaire,quote,argua...           6.660   \n",
       "2  {reading,great,biography,ben,franklin,isaacson...           6.660   \n",
       "3  {yum,even,better,deep,fried,butter,yeah,really...           5.580   \n",
       "4  {model,options,performance,red,black,deliver,c...           5.514   \n",
       "\n",
       "   next_day_close  close_price_diff  \n",
       "0           6.660             0.112  \n",
       "1           6.884             0.224  \n",
       "2           6.884             0.224  \n",
       "3           5.554            -0.026  \n",
       "4           5.580             0.066  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_price = tweets_price[tweets_price.tweet_tokens.str.count(',') > 1] # More than two words in tweet\n",
    "tweets_price.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96593c41",
   "metadata": {},
   "source": [
    "## A - Classification: Which tweets increase stock price vs decrease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f35a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries for model\n",
    "\n",
    "#CountVectorizer = this takes in a list and counts how many times it appears\n",
    "#TfidfTransformer = frequency of word in a tweet as compared to other tweets\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(C=0.01, random_state=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3c89720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(tweets_price, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54d3a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variables\n",
    "X_train = train_df.tweet_tokens.tolist()\n",
    "y_train = (train_df['close_price_diff'] > 0).astype(int).values\n",
    "X_test = test_df.tweet_tokens.tolist()\n",
    "y_test = (test_df['close_price_diff'] > 0).astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8c6487e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(preprocessor=<function <lambda> at 0x11bb950d0>,\n",
       "                                 tokenizer=<function <lambda> at 0x11bc9aaf0>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(C=0.01, random_state=1))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify text data\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da6b4cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82f67577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predicted probability\n",
    "predicted_proba_test = text_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e8dac268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_positive_tweet</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>stock_price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.566446</td>\n",
       "      <td>{First test flight hop of our Grasshopper VTVL rocket!  http://t.co/oomI5vSB}</td>\n",
       "      <td>2012-09-22</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0.566264</td>\n",
       "      <td>{Thank you, South Texas for your support! This is the gateway to Mars., Life, the Universe and Everything  https://t.co/1ZCzInfc4u}</td>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>5.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.566229</td>\n",
       "      <td>{Just want to say thanks to customers &amp;amp; investors that took a chance on Tesla through the long, dark night. We wouldn't be here without you., @westcoastbill Thanks Bill!}</td>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>2.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>0.566174</td>\n",
       "      <td>{Great meme review hosted by Will Smith, Highest reentry heating to date. Burning metal sparks from base heat shield visible in landing video. Fourth relight scheduled for April.}</td>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>1.508003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>0.566141</td>\n",
       "      <td>{From thence to Mars,\\nAnd hence the Stars., Creating the city of Starbase, Texas, Horses are even self-driving! https://t.co/qPJrCFGs8J, Scammers &amp;amp; crypto should get a room}</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>-65.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.566067</td>\n",
       "      <td>{Awesome moose sculpture! ‚ô•Ô∏èüá≥üá¥  https://t.co/CegEEHL4wz, Testing metallic heat shield at 1100C (2000F) @SpaceX  https://t.co/frP5eZ5a0z, If test flight of üêâ goes well next month, @NASA üë®‚ÄçüöÄ üë©‚ÄçüöÄ will üöÄ to @Space_Station this summer!}</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>0.974003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.566025</td>\n",
       "      <td>{US govt testing by @NHTSAgov finds Model X to be the safest SUV in history by significant margin  https://t.co/zAdb5FQPEI}</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>4.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>0.566024</td>\n",
       "      <td>{Great progress by Starship Cape team. Started several months behind, but catching up fast. This will be a super fun race to orbit, moon &amp;amp; Mars!}</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>1.019997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.565899</td>\n",
       "      <td>{We just got banned in West Virginia. Oh no.  http://t.co/gNztPDNtVT}</td>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>2.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0.565860</td>\n",
       "      <td>{Tesla piece on the physics of car safety coming soon for those interested in technical details, .@NHTSAgov will post final safety probability stats soon. Model 3 has a shot at being safest car ever tested.}</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0.015999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      proba_positive_tweet  \\\n",
       "116               0.566446   \n",
       "1541              0.566264   \n",
       "218               0.566229   \n",
       "1123              0.566174   \n",
       "1593              0.566141   \n",
       "1100              0.566067   \n",
       "764               0.566025   \n",
       "1231              0.566024   \n",
       "434               0.565899   \n",
       "1012              0.565860   \n",
       "\n",
       "                                                                                                                                                                                                                                   tweet_text  \\\n",
       "116                                                                                                                                                             {First test flight hop of our Grasshopper VTVL rocket!  http://t.co/oomI5vSB}   \n",
       "1541                                                                                                      {Thank you, South Texas for your support! This is the gateway to Mars., Life, the Universe and Everything  https://t.co/1ZCzInfc4u}   \n",
       "218                                                            {Just want to say thanks to customers &amp; investors that took a chance on Tesla through the long, dark night. We wouldn't be here without you., @westcoastbill Thanks Bill!}   \n",
       "1123                                                      {Great meme review hosted by Will Smith, Highest reentry heating to date. Burning metal sparks from base heat shield visible in landing video. Fourth relight scheduled for April.}   \n",
       "1593                                                       {From thence to Mars,\\nAnd hence the Stars., Creating the city of Starbase, Texas, Horses are even self-driving! https://t.co/qPJrCFGs8J, Scammers &amp; crypto should get a room}   \n",
       "1100  {Awesome moose sculpture! ‚ô•Ô∏èüá≥üá¥  https://t.co/CegEEHL4wz, Testing metallic heat shield at 1100C (2000F) @SpaceX  https://t.co/frP5eZ5a0z, If test flight of üêâ goes well next month, @NASA üë®‚ÄçüöÄ üë©‚ÄçüöÄ will üöÄ to @Space_Station this summer!}   \n",
       "764                                                                                                               {US govt testing by @NHTSAgov finds Model X to be the safest SUV in history by significant margin  https://t.co/zAdb5FQPEI}   \n",
       "1231                                                                                    {Great progress by Starship Cape team. Started several months behind, but catching up fast. This will be a super fun race to orbit, moon &amp; Mars!}   \n",
       "434                                                                                                                                                                     {We just got banned in West Virginia. Oh no.  http://t.co/gNztPDNtVT}   \n",
       "1012                          {Tesla piece on the physics of car safety coming soon for those interested in technical details, .@NHTSAgov will post final safety probability stats soon. Model 3 has a shot at being safest car ever tested.}   \n",
       "\n",
       "     tweet_date  stock_price_change  \n",
       "116  2012-09-22            0.128000  \n",
       "1541 2020-12-10            5.510010  \n",
       "218  2013-05-08            2.778000  \n",
       "1123 2019-02-22            1.508003  \n",
       "1593 2021-03-02          -65.229980  \n",
       "1100 2019-01-25            0.974003  \n",
       "764  2017-06-13            4.330002  \n",
       "1231 2019-08-06            1.019997  \n",
       "434  2015-04-04            2.419998  \n",
       "1012 2018-09-20            0.015999  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding results into DataFrame\n",
    "results_test = pd.DataFrame({\n",
    "    'proba_positive_tweet': predicted_proba_test,\n",
    "    'tweet_text': test_df['tweet_text'],\n",
    "    'tweet_date': test_df['tweet_date'],\n",
    "    'stock_price_change': test_df['close_price_diff'],\n",
    "}).sort_values('proba_positive_tweet', ascending=False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "results_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9296f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.to_csv('data/results_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
