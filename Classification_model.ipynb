{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6e8aa4",
   "metadata": {},
   "source": [
    "# Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f8b11",
   "metadata": {},
   "source": [
    "## Model Plan\n",
    "- Prepare the dataframe with columns: tweet_text, price_previous day, price_next day, price_diff\n",
    "- Preprocess the tweet text into features (countVectorier, tfidf)\n",
    "- Classification: LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a412b2b",
   "metadata": {},
   "source": [
    "### Query the dataframe with columns: tweet_text, price_previous day, price_next day, price_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af82539e-5e32-4859-b979-65da960922b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries:\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect \n",
    "from config import db_password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af61d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create engine\n",
    "engine = create_engine(f\"postgresql://postgres:{db_password}@127.0.0.1:5432/twitter_vs_stocks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffe9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new table for model, preprocessing the data\n",
    "\n",
    "tweets_price = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "        SELECT \n",
    "            tweets.date AS tweet_date,\n",
    "            tweets.text AS tweet_text,\n",
    "            tweets.tokenized_text AS tweet_tokens,\n",
    "            COALESCE(stock_prev.close, stock_prev_prev.close, stock_prev_prev_prev.close) AS prev_day_close,\n",
    "            COALESCE(stock_next.close, stock_next_next.close, stock_next_next_next.close) AS next_day_close\n",
    "        FROM tweets_text tweets\n",
    "        LEFT JOIN stock stock_prev\n",
    "            ON (tweets.date - INTERVAL '1 day') = stock_prev.date\n",
    "        LEFT JOIN stock stock_prev_prev\n",
    "            ON (tweets.date - INTERVAL '2 day') = stock_prev_prev.date\n",
    "        LEFT JOIN stock stock_prev_prev_prev\n",
    "            ON (tweets.date - INTERVAL '3 day') = stock_prev_prev_prev.date\n",
    "        LEFT JOIN stock stock_next\n",
    "            ON (tweets.date + INTERVAL '1 day') = stock_next.date\n",
    "        LEFT JOIN stock stock_next_next\n",
    "            ON (tweets.date + INTERVAL '2 day') = stock_next_next.date\n",
    "        LEFT JOIN stock stock_next_next_next\n",
    "            ON (tweets.date + INTERVAL '3 day') = stock_next_next_next.date\n",
    "        WHERE tweets.date > '2011-01-01' AND tweets.tokenized_text != '{}'\n",
    "        ORDER BY tweets.date\n",
    "    \"\"\",\n",
    "    con=engine\n",
    ")\n",
    "\n",
    "tweets_price.dropna(inplace=True)\n",
    "\n",
    "#Computing difference between the stock price before the date of tweet and after the post. \n",
    "tweets_price['close_price_diff'] = tweets_price['next_day_close'] - tweets_price['prev_day_close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a831805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_tokens</th>\n",
       "      <th>prev_day_close</th>\n",
       "      <th>next_day_close</th>\n",
       "      <th>close_price_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "      <td>{made,volume,model,go,need,work,miniature,ston...</td>\n",
       "      <td>6.548</td>\n",
       "      <td>6.660</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "      <td>{total,non,sequitur,great,voltaire,quote,argua...</td>\n",
       "      <td>6.660</td>\n",
       "      <td>6.884</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "      <td>{reading,great,biography,ben,franklin,isaacson...</td>\n",
       "      <td>6.660</td>\n",
       "      <td>6.884</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "      <td>{yum,even,better,deep,fried,butter,yeah,really...</td>\n",
       "      <td>5.580</td>\n",
       "      <td>5.554</td>\n",
       "      <td>-0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "      <td>{model,options,performance,red,black,deliver,c...</td>\n",
       "      <td>5.514</td>\n",
       "      <td>5.580</td>\n",
       "      <td>0.066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tweet_date                                         tweet_text  \\\n",
       "0 2011-12-01  {I made the volume on the Model S  http://t.co...   \n",
       "1 2011-12-03  {That was a total non sequitur btw, Great Volt...   \n",
       "2 2011-12-04  {Am reading a great biography of Ben Franklin ...   \n",
       "3 2011-12-21  {Yum! Even better than deep fried butter:  htt...   \n",
       "4 2011-12-22  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                        tweet_tokens  prev_day_close  \\\n",
       "0  {made,volume,model,go,need,work,miniature,ston...           6.548   \n",
       "1  {total,non,sequitur,great,voltaire,quote,argua...           6.660   \n",
       "2  {reading,great,biography,ben,franklin,isaacson...           6.660   \n",
       "3  {yum,even,better,deep,fried,butter,yeah,really...           5.580   \n",
       "4  {model,options,performance,red,black,deliver,c...           5.514   \n",
       "\n",
       "   next_day_close  close_price_diff  \n",
       "0           6.660             0.112  \n",
       "1           6.884             0.224  \n",
       "2           6.884             0.224  \n",
       "3           5.554            -0.026  \n",
       "4           5.580             0.066  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_price = tweets_price[tweets_price.tweet_tokens.str.count(',') > 1] # More than two words in tweet\n",
    "tweets_price.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96593c41",
   "metadata": {},
   "source": [
    "## A - Classification: Which tweets increase stock price vs decrease\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f35a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries for model\n",
    "\n",
    "#CountVectorizer = this takes in a list and counts how many times it appears\n",
    "#TfidfTransformer = frequency of word in a tweet as compared to other tweets\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression(C=0.01, random_state=1)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3c89720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(tweets_price, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d3a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variables\n",
    "X_train = train_df.tweet_tokens.tolist()\n",
    "y_train = (train_df['close_price_diff'] > 0).astype(int).values\n",
    "X_test = test_df.tweet_tokens.tolist()\n",
    "y_test = (test_df['close_price_diff'] > 0).astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c6487e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 CountVectorizer(preprocessor=<function <lambda> at 0x11f9ceca0>,\n",
       "                                 tokenizer=<function <lambda> at 0x122983e50>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(C=0.01, random_state=1))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify text data\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da6b4cfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5454545454545454"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f67577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predicted probability\n",
    "predicted_proba_test = text_clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8dac268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba_positive_tweet</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>stock_price_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.566446</td>\n",
       "      <td>{First test flight hop of our Grasshopper VTVL rocket!  http://t.co/oomI5vSB}</td>\n",
       "      <td>2012-09-22</td>\n",
       "      <td>0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>0.566264</td>\n",
       "      <td>{Thank you, South Texas for your support! This is the gateway to Mars., Life, the Universe and Everything  https://t.co/1ZCzInfc4u}</td>\n",
       "      <td>2020-12-10</td>\n",
       "      <td>5.510010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0.566229</td>\n",
       "      <td>{Just want to say thanks to customers &amp;amp; investors that took a chance on Tesla through the long, dark night. We wouldn't be here without you., @westcoastbill Thanks Bill!}</td>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>2.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>0.566174</td>\n",
       "      <td>{Great meme review hosted by Will Smith, Highest reentry heating to date. Burning metal sparks from base heat shield visible in landing video. Fourth relight scheduled for April.}</td>\n",
       "      <td>2019-02-22</td>\n",
       "      <td>1.508003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>0.566141</td>\n",
       "      <td>{From thence to Mars,\\nAnd hence the Stars., Creating the city of Starbase, Texas, Horses are even self-driving! https://t.co/qPJrCFGs8J, Scammers &amp;amp; crypto should get a room}</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>-65.229980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>0.566067</td>\n",
       "      <td>{Awesome moose sculpture! ‚ô•Ô∏èüá≥üá¥  https://t.co/CegEEHL4wz, Testing metallic heat shield at 1100C (2000F) @SpaceX  https://t.co/frP5eZ5a0z, If test flight of üêâ goes well next month, @NASA üë®‚ÄçüöÄ üë©‚ÄçüöÄ will üöÄ to @Space_Station this summer!}</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>0.974003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0.566025</td>\n",
       "      <td>{US govt testing by @NHTSAgov finds Model X to be the safest SUV in history by significant margin  https://t.co/zAdb5FQPEI}</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>4.330002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>0.566024</td>\n",
       "      <td>{Great progress by Starship Cape team. Started several months behind, but catching up fast. This will be a super fun race to orbit, moon &amp;amp; Mars!}</td>\n",
       "      <td>2019-08-06</td>\n",
       "      <td>1.019997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.565899</td>\n",
       "      <td>{We just got banned in West Virginia. Oh no.  http://t.co/gNztPDNtVT}</td>\n",
       "      <td>2015-04-04</td>\n",
       "      <td>2.419998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>0.565860</td>\n",
       "      <td>{Tesla piece on the physics of car safety coming soon for those interested in technical details, .@NHTSAgov will post final safety probability stats soon. Model 3 has a shot at being safest car ever tested.}</td>\n",
       "      <td>2018-09-20</td>\n",
       "      <td>0.015999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      proba_positive_tweet  \\\n",
       "116               0.566446   \n",
       "1541              0.566264   \n",
       "218               0.566229   \n",
       "1123              0.566174   \n",
       "1593              0.566141   \n",
       "1100              0.566067   \n",
       "764               0.566025   \n",
       "1231              0.566024   \n",
       "434               0.565899   \n",
       "1012              0.565860   \n",
       "\n",
       "                                                                                                                                                                                                                                   tweet_text  \\\n",
       "116                                                                                                                                                             {First test flight hop of our Grasshopper VTVL rocket!  http://t.co/oomI5vSB}   \n",
       "1541                                                                                                      {Thank you, South Texas for your support! This is the gateway to Mars., Life, the Universe and Everything  https://t.co/1ZCzInfc4u}   \n",
       "218                                                            {Just want to say thanks to customers &amp; investors that took a chance on Tesla through the long, dark night. We wouldn't be here without you., @westcoastbill Thanks Bill!}   \n",
       "1123                                                      {Great meme review hosted by Will Smith, Highest reentry heating to date. Burning metal sparks from base heat shield visible in landing video. Fourth relight scheduled for April.}   \n",
       "1593                                                       {From thence to Mars,\\nAnd hence the Stars., Creating the city of Starbase, Texas, Horses are even self-driving! https://t.co/qPJrCFGs8J, Scammers &amp; crypto should get a room}   \n",
       "1100  {Awesome moose sculpture! ‚ô•Ô∏èüá≥üá¥  https://t.co/CegEEHL4wz, Testing metallic heat shield at 1100C (2000F) @SpaceX  https://t.co/frP5eZ5a0z, If test flight of üêâ goes well next month, @NASA üë®‚ÄçüöÄ üë©‚ÄçüöÄ will üöÄ to @Space_Station this summer!}   \n",
       "764                                                                                                               {US govt testing by @NHTSAgov finds Model X to be the safest SUV in history by significant margin  https://t.co/zAdb5FQPEI}   \n",
       "1231                                                                                    {Great progress by Starship Cape team. Started several months behind, but catching up fast. This will be a super fun race to orbit, moon &amp; Mars!}   \n",
       "434                                                                                                                                                                     {We just got banned in West Virginia. Oh no.  http://t.co/gNztPDNtVT}   \n",
       "1012                          {Tesla piece on the physics of car safety coming soon for those interested in technical details, .@NHTSAgov will post final safety probability stats soon. Model 3 has a shot at being safest car ever tested.}   \n",
       "\n",
       "     tweet_date  stock_price_change  \n",
       "116  2012-09-22            0.128000  \n",
       "1541 2020-12-10            5.510010  \n",
       "218  2013-05-08            2.778000  \n",
       "1123 2019-02-22            1.508003  \n",
       "1593 2021-03-02          -65.229980  \n",
       "1100 2019-01-25            0.974003  \n",
       "764  2017-06-13            4.330002  \n",
       "1231 2019-08-06            1.019997  \n",
       "434  2015-04-04            2.419998  \n",
       "1012 2018-09-20            0.015999  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding results into DataFrame\n",
    "results_test = pd.DataFrame({\n",
    "    'proba_positive_tweet': predicted_proba_test,\n",
    "    'tweet_text': test_df['tweet_text'],\n",
    "    'tweet_date': test_df['tweet_date'],\n",
    "    'stock_price_change': test_df['close_price_diff'],\n",
    "}).sort_values('proba_positive_tweet', ascending=False)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "results_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9296f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test.to_csv('Resources/Data/results_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2850c02d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
