{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c5c006",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation (LDA) Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd0a91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>1330</td>\n",
       "      <td>87</td>\n",
       "      <td>597</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>1349</td>\n",
       "      <td>132</td>\n",
       "      <td>206</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  like_count  reply_count  retweet_count  \\\n",
       "0  2011-12-01         267           63             24   \n",
       "1  2011-12-03          82           38             31   \n",
       "2  2011-12-04          65           17              9   \n",
       "3  2011-12-21        1330           87            597   \n",
       "4  2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \n",
       "0  {I made the volume on the Model S  http://t.co...  \n",
       "1  {That was a total non sequitur btw, Great Volt...  \n",
       "2  {Am reading a great biography of Ben Franklin ...  \n",
       "3  {Yum! Even better than deep fried butter:  htt...  \n",
       "4  {Model S options are out! Performance in red a...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load to the data\n",
    "import pandas as pd\n",
    "df_tweets = pd.read_csv('Resources/Data/tweets_data_lda.csv')\n",
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffae5f8",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "**Preprocess the data by making it all lowercase. Remove a reasonable set of stopwords from the dataset and tokenize. Then, report the 10 most common words and their count. We need to iterate this process, adding some stop words as we understand the structure of the data. Justify additional stop words we've added.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "441873e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gobinaththangaiya/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>267</td>\n",
       "      <td>63</td>\n",
       "      <td>24</td>\n",
       "      <td>{I made the volume on the Model S  http://t.co...</td>\n",
       "      <td>{i made the volume on the model s go to 11. no...</td>\n",
       "      <td>[made, volume, model, go, need, work, miniatur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-12-03</td>\n",
       "      <td>82</td>\n",
       "      <td>38</td>\n",
       "      <td>31</td>\n",
       "      <td>{That was a total non sequitur btw, Great Volt...</td>\n",
       "      <td>{that was a total non sequitur btw, great volt...</td>\n",
       "      <td>[total, non, sequitur, great, voltaire, quote,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>65</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>{Am reading a great biography of Ben Franklin ...</td>\n",
       "      <td>{am reading a great biography of ben franklin ...</td>\n",
       "      <td>[reading, great, biography, ben, franklin, isa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-12-21</td>\n",
       "      <td>1330</td>\n",
       "      <td>87</td>\n",
       "      <td>597</td>\n",
       "      <td>{Yum! Even better than deep fried butter:  htt...</td>\n",
       "      <td>{yum! even better than deep fried butter: yeah...</td>\n",
       "      <td>[yum, even, better, deep, fried, butter, yeah,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-12-22</td>\n",
       "      <td>1349</td>\n",
       "      <td>132</td>\n",
       "      <td>206</td>\n",
       "      <td>{Model S options are out! Performance in red a...</td>\n",
       "      <td>{model s options are out! performance in red a...</td>\n",
       "      <td>[model, options, performance, red, black, deli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  like_count  reply_count  retweet_count  \\\n",
       "0  2011-12-01         267           63             24   \n",
       "1  2011-12-03          82           38             31   \n",
       "2  2011-12-04          65           17              9   \n",
       "3  2011-12-21        1330           87            597   \n",
       "4  2011-12-22        1349          132            206   \n",
       "\n",
       "                                                text  \\\n",
       "0  {I made the volume on the Model S  http://t.co...   \n",
       "1  {That was a total non sequitur btw, Great Volt...   \n",
       "2  {Am reading a great biography of Ben Franklin ...   \n",
       "3  {Yum! Even better than deep fried butter:  htt...   \n",
       "4  {Model S options are out! Performance in red a...   \n",
       "\n",
       "                                   preprocessed_text  \\\n",
       "0  {i made the volume on the model s go to 11. no...   \n",
       "1  {that was a total non sequitur btw, great volt...   \n",
       "2  {am reading a great biography of ben franklin ...   \n",
       "3  {yum! even better than deep fried butter: yeah...   \n",
       "4  {model s options are out! performance in red a...   \n",
       "\n",
       "                                      tokenized_text  \n",
       "0  [made, volume, model, go, need, work, miniatur...  \n",
       "1  [total, non, sequitur, great, voltaire, quote,...  \n",
       "2  [reading, great, biography, ben, franklin, isa...  \n",
       "3  [yum, even, better, deep, fried, butter, yeah,...  \n",
       "4  [model, options, performance, red, black, deli...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Pre-processing and make the tweets all lowercase and remove stopwords.\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from datetime import datetime\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import math\n",
    "import math\n",
    "\n",
    "twitter_df = df_tweets.copy()\n",
    "\n",
    "# lower the tweets\n",
    "twitter_df['preprocessed_text'] = twitter_df['text'].str.lower()\n",
    "\n",
    "# remove apostrophe from words and url\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"('[a-z]+)\\s\", \" \", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(')\\s\", \" \", row) for row in twitter_df['preprocessed_text']]\n",
    "twitter_df['preprocessed_text'] = [re.sub(\"(?:https:\\/\\/\\S+)\\s\", \"\", row) for row in twitter_df['preprocessed_text']]\n",
    "\n",
    "                                      \n",
    "# filter out rest URLs\n",
    "url_re = '(?:https?:\\/\\/)?(?:[^?\\/\\s]+[?\\/])(.*)'\n",
    "twitter_df['preprocessed_text'] = twitter_df['preprocessed_text'].apply(lambda row: ' '.join([word for word in row.split() if (not re.match(url_re, word))]))\n",
    "\n",
    "# tokenize the tweets\n",
    "tokenizer = RegexpTokenizer('[a-zA-Z]\\w+\\'?\\w*')\n",
    "twitter_df['tokenized_text'] = twitter_df['preprocessed_text'].apply(lambda row: tokenizer.tokenize(row))\n",
    "\n",
    "#create an object of class PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# apply stemming\n",
    "twitter_df['preprocessed_text'] = [porter.stem(row) for row in twitter_df['preprocessed_text']]   \n",
    "\n",
    "# filter out stop words\n",
    "en_stop_words = nltk.corpus.stopwords.words('english')\n",
    "additional_stop_words =['amp', 'rt', 'th','co', 're', 've', 'kim', 'daca', 'us', 'it', 'th', 'you', 'haha', 'st', 'et', 'so', 'iii', 'also', 've', 'la', 're', 'the', 'https', 'wow', 'actually', 'due', 'ft', 'pcr', 'via', 'am', 'gt', 'com', 'since', 'in', 'me', 'and', 'btw', 'yesterday', 'ii', 'inu', 'on', 'http', 'to', 'vs', 'rd', 'ur', 'of', 'bs', 'km', 'est', 'em', 'lz', 'kms', 'aft', 'nd',  'here’s', 're', 'mqxfakpzf' 'mph', 'ht', 'etc', 'dm', 'doo']\n",
    "en_stop_words.extend(additional_stop_words)\n",
    "\n",
    "twitter_df['tokenized_text'] = twitter_df['tokenized_text'].apply(lambda row: [word for word in row if (not word in en_stop_words)])\n",
    "\n",
    "df_tweets_clean = twitter_df.copy()\n",
    "df_tweets_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d3c3a",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "If we want to classify text on a topic basis, we often do not want to look at the sequences of words. We do not want to classify text. Instead, we present the text as an unordered word package, ignoring its original position in the text and keeping its frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd9e3757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define function for counting words\n",
    "def get_most_freq_words(str, n=None):\n",
    "    vect = CountVectorizer().fit(str)\n",
    "    bag_of_words = vect.transform(str)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    freq =sorted(freq, key = lambda x: x[1], reverse=True)\n",
    "    return freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d2520cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musked used 8197 words in his tweets.\n",
      "The most popular words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tesla', 629),\n",
       " ('model', 260),\n",
       " ('spacex', 245),\n",
       " ('good', 180),\n",
       " ('launch', 174),\n",
       " ('rocket', 166),\n",
       " ('car', 160),\n",
       " ('falcon', 159),\n",
       " ('like', 151),\n",
       " ('time', 129)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count words in tweets\n",
    "words_in_tweets = get_most_freq_words([ word for tweet in df_tweets_clean.tokenized_text for word in tweet])\n",
    "print(f'Elon Musked used {len(words_in_tweets)} words in his tweets.')\n",
    "print(f'The most popular words:')\n",
    "words_in_tweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22f7208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tesla</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spacex</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>good</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>launch</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Word  Count\n",
       "0   tesla    629\n",
       "1   model    260\n",
       "2  spacex    245\n",
       "3    good    180\n",
       "4  launch    174"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "words_count = pd.DataFrame(words_in_tweets, columns=['Word', 'Count'])\n",
    "words_count.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14e06c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export word counts to csv\n",
    "words_count.to_csv('Resources/Data/words_count.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45294f4",
   "metadata": {},
   "source": [
    "### Identify the number of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5440be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -2.4865930772831146\n",
      "2 -2.608549868636458\n",
      "3 -2.5497857502085792\n",
      "4 -2.8021578786222143\n",
      "5 -3.1069084749596256\n",
      "6 -3.6762588675797794\n"
     ]
    }
   ],
   "source": [
    "# build a dictionary where for each tweet, each word has its own id.\n",
    "tweets_dictionary = Dictionary(df_tweets_clean.tokenized_text)\n",
    "\n",
    "# build the corpus i.e. vectors with the number of occurence of each word per tweet\n",
    "tweets_corpus = [tweets_dictionary.doc2bow(tweet) for tweet in df_tweets_clean.tokenized_text]\n",
    "\n",
    "# compute coherence\n",
    "tweets_coherence = []\n",
    "for nb_topics in range(1,10):\n",
    "    lda = LdaModel(tweets_corpus, num_topics = nb_topics, alpha= 'auto', eta='auto', id2word = tweets_dictionary, passes=10)\n",
    "    cohm = CoherenceModel(model=lda, corpus=tweets_corpus, dictionary=tweets_dictionary, coherence='u_mass')\n",
    "    coh = cohm.get_coherence()\n",
    "    tweets_coherence.append(coh)\n",
    "    print(nb_topics,coh)\n",
    "\n",
    "# visualize coherence\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(range(1, 10),tweets_coherence)\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence Score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654d40ed",
   "metadata": {},
   "source": [
    "The average coherence score per topic for a variety of models trained with varying numbers of topics is shown below. The number of topics for which the average score reaches a peak point is the perfect balance we seek. As a result, our best guess for the number of topics is around two (k =2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50820618",
   "metadata": {},
   "source": [
    "### Running the LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba231ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "k = 2\n",
    "tweets_lda = LdaModel(tweets_corpus, num_topics = k, id2word = tweets_dictionary, passes=10)\n",
    "\n",
    "def plot_top_words(lda=tweets_lda, nb_topics=k, nb_words=7):\n",
    "    top_words = [[word for word,_ in lda.show_topic(topic_id, topn=50)] for topic_id in range(lda.num_topics)]\n",
    "    top_betas = [[beta for _,beta in lda.show_topic(topic_id, topn=50)] for topic_id in range(lda.num_topics)]\n",
    "\n",
    "    gs  = gridspec.GridSpec(round(math.sqrt(k))+1,round(math.sqrt(k))+1)\n",
    "    gs.update(wspace=0.5, hspace=0.5)\n",
    "    plt.figure(figsize=(20,15))\n",
    "    for i in range(nb_topics):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.barh(range(nb_words), top_betas[i][:nb_words], align='center',color='pink', ecolor='black')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_yticks(range(nb_words))\n",
    "        ax.set_yticklabels(top_words[i][:nb_words])\n",
    "        plt.title(\"Topic \"+str(i))\n",
    "        \n",
    "  \n",
    "plot_top_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f203e",
   "metadata": {},
   "source": [
    "### We can determine topics based on key words :\n",
    "### Topic 0 - SpaceX\n",
    "### Topic 1 - Tesla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338d658e",
   "metadata": {},
   "source": [
    "Reference; https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-by-example-3b22cd10c835, date; 2021-07-21, time; 2.25 pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bebfca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
